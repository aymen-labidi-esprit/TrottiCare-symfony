<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Support Vocal (POC - Frontend OpenAI)</title>

  <!-- Add Bootstrap Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">

  <style>
    /* --- Styles (Keep the CSS from the previous answer) --- */
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;700&display=swap');
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { font-family: 'Cairo', sans-serif; background-color: #f0f2f5; }
    .bi { display: inline-block; vertical-align: -.125em; fill: currentColor; }
    .voice-support-container { max-width: 500px; margin: 2rem auto; padding: 25px; border-radius: 12px; box-shadow: 0 5px 15px rgba(0, 0, 0, 0.12); background-color: #fff; direction: rtl; }
    .voice-support-header { text-align: center; margin-bottom: 25px; padding-bottom: 15px; border-bottom: 1px solid #eee; }
    .voice-support-header h2 { color: #34495e; margin-bottom: 8px; font-weight: 600; }
    .voice-support-header p { color: #7f8c8d; margin: 0; font-size: 0.9rem; }
    .voice-support-controls { display: flex; flex-direction: column; align-items: center; margin-bottom: 25px; }
    .record-button { display: inline-flex; align-items: center; justify-content: center; padding: 14px 30px; background-color: #e74c3c; color: white; border: none; border-radius: 50px; cursor: pointer; transition: all 0.3s ease; font-size: 16px; font-weight: 600; box-shadow: 0 3px 8px rgba(231, 76, 60, 0.4); margin-bottom: 15px; }
    .record-button:hover { background-color: #c0392b; transform: translateY(-2px); box-shadow: 0 5px 12px rgba(192, 57, 43, 0.5); }
    .record-button.recording { background-color: #2980b9; /* Blue while recording */ animation: recording-pulse 1.5s infinite; box-shadow: 0 3px 8px rgba(41, 128, 185, 0.4); }
    .record-button.processing { background-color: #f39c12; /* Orange while processing */ cursor: wait; box-shadow: 0 3px 8px rgba(243, 156, 18, 0.4); }
    @keyframes recording-pulse { 0% { box-shadow: 0 0 0 0 rgba(41, 128, 185, 0.6); } 70% { box-shadow: 0 0 0 10px rgba(41, 128, 185, 0); } 100% { box-shadow: 0 0 0 0 rgba(41, 128, 185, 0); } }
    .record-icon { font-size: 1.2em; margin-left: 8px; }
    .voice-status { color: #7f8c8d; font-size: 14px; margin-top: 8px; text-align: center; min-height: 20px; }
    .conversation-container { display: flex; flex-direction: column; gap: 12px; height: 350px; overflow-y: auto; padding: 15px; border-radius: 8px; background-color: #f7f9fa; border: 1px solid #e8eaed; scrollbar-width: thin; scrollbar-color: #bdc3c7 #f7f9fa; }
    .conversation-container::-webkit-scrollbar { width: 6px; } .conversation-container::-webkit-scrollbar-track { background: #f7f9fa; } .conversation-container::-webkit-scrollbar-thumb { background-color: #bdc3c7; border-radius: 3px; }
    .message { padding: 10px 16px; border-radius: 18px; max-width: 80%; box-shadow: 0 1px 2px rgba(0, 0, 0, 0.08); position: relative; line-height: 1.5; word-wrap: break-word; animation: fade-in 0.4s ease-out; }
    @keyframes fade-in { from { opacity: 0; transform: scale(0.95); } to { opacity: 1; transform: scale(1); } }
    .user-message { align-self: flex-start; background-color: #3498db; color: white; border-bottom-left-radius: 4px; }
    .assistant-message { align-self: flex-end; background-color: #ecf0f1; color: #34495e; border-bottom-right-radius: 4px; }
    .message-time { font-size: 10px; color: #95a5a6; margin-top: 5px; display: block; text-align: inherit; }
    .user-message .message-time { text-align: left; color: rgba(255,255,255,0.7);} .assistant-message .message-time { text-align: right; }
    .loading { align-self: flex-end; padding: 10px 16px; border-radius: 18px; border-bottom-right-radius: 4px; background-color: #ecf0f1; color: #7f8c8d; font-style: italic; max-width: 50%; margin-bottom: 12px; display: flex; align-items: center; }
    .loading-dots span { display: inline-block; width: 6px; height: 6px; border-radius: 50%; background-color: #7f8c8d; margin: 0 2px; animation: bounce 1.4s infinite ease-in-out both; }
    .loading-dots span:nth-child(1) { animation-delay: -0.32s; } .loading-dots span:nth-child(2) { animation-delay: -0.16s; } .loading-dots span:nth-child(3) { animation-delay: 0s; }
    @keyframes bounce { 0%, 80%, 100% { transform: scale(0); } 40% { transform: scale(1.0); } }
    .hidden { display: none !important; }
    .me-2 { margin-left: 0.5rem; } .ms-2 { margin-right: 0.5rem; }
    .alert-danger { margin-top: 20px; text-align: center; font-size: 12px; color: #dc3545; padding: 10px; border: 1px solid #f5c6cb; background-color: #f8d7da; border-radius: 5px;}
  </style>
</head>
<body>

<div class="container mt-4 mb-5">
  <div class="voice-support-container">
    <div class="voice-support-header">
      <h2>مرحبا بيك! كيفاش نجم نعاونك؟</h2>
      <p>اضغط على الميكرو و أحكي</p> <!-- Updated instruction -->
    </div>

    <div class="voice-support-controls">
      <button id="recordButton" class="record-button">
        <i class="bi bi-mic-fill record-icon"></i>
        <span class="button-text">إبدأ التسجيل</span> <!-- Start Recording -->
      </button>
      <div class="voice-status" id="voiceStatus">مستعد للمساعدة</div>
    </div>

    <div class="conversation-container" id="conversationContainer">
      <!-- Messages appear here -->
    </div>
  </div>

  <div class="alert-danger">
  </div>
</div>

<script>
  class TunisianRealtimeVoicePOC {
    constructor() {
      this.isRecording = false;
      this.isProcessing = false; // Separate flag for processing stages
      this.mediaRecorder = null;
      this.audioChunks = [];
      this.currentAudioPlayer = null; // To manage audio playback

      // !!! --- SECURITY WARNING --- !!!
      this.apiKey = "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"; // <-- PASTE YOUR KEY HERE FOR POC ONLY

      this.sttApiUrl = 'https://api.openai.com/v1/audio/transcriptions';
      this.chatApiUrl = 'https://api.openai.com/v1/chat/completions';
      this.ttsApiUrl = 'https://api.openai.com/v1/audio/speech';

      this.phrases = {
        error: "سامحني، فما مشكلة فنية.",
        notUnderstood: "سامحني، ما فهمتش. تنجم تعاود؟",
        ready: "مستعد للمساعدة",
        listening: "نسمع فيك...",
        transcribing: "جاري تحليل الصوت...",
        thinking: "لحظة بربي نفكر...",
        speaking: "المساعد يتحدث...",
        micError: "مشكلة في الوصول للميكروفون.",
        apiKeyError: "خطأ: مفتاح API غير مهيأ.",
      };

      this.conversationHistory = []; // Store chat history

      this.initElements();
      this.initEventListeners();
      this.checkApiKey();
      console.log("TunisianRealtimeVoicePOC initialized.");
    }

    initElements() {
      this.recordButton = document.getElementById('recordButton');
      this.buttonText = this.recordButton?.querySelector('.button-text');
      this.voiceStatus = document.getElementById('voiceStatus');
      this.conversationContainer = document.getElementById('conversationContainer');

      if (!this.recordButton || !this.voiceStatus || !this.conversationContainer || !this.buttonText) {
        console.error("Essential UI elements not found!");
      }
    }

    initEventListeners() {
      // Toggle recording on button click
      this.recordButton?.addEventListener('click', () => this.toggleRecording());
    }

    checkApiKey() {
      if (!this.apiKey || this.apiKey.includes("YOUR_KEY_HERE")) {
        console.error("CRITICAL: OpenAI API Key is missing or is a placeholder!");
        this.displayErrorOnPage(this.phrases.apiKeyError);
        return false;
      }
      return true;
    }

    displayErrorOnPage(message) {
      if (this.voiceStatus) {
        this.voiceStatus.textContent = message;
        this.voiceStatus.style.color = '#dc3545';
      }
      if (this.recordButton) {
        this.recordButton.disabled = true;
      }
    }

    async toggleRecording() {
      if (this.isProcessing) return; // Don't allow action while processing

      if (!this.checkApiKey()) return; // Stop if key is invalid

      if (!this.isRecording) {
        await this.startRecording();
      } else {
        await this.stopRecordingAndProcess();
      }
    }

    async startRecording() {
      console.log("Attempting to start recording...");
      if (this.isRecording) return;

      try {
        // Request microphone access
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        this.audioChunks = []; // Reset chunks
        // Determine preferred MIME type
        const options = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
                ? { mimeType: 'audio/webm;codecs=opus' }
                : MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')
                        ? { mimeType: 'audio/ogg;codecs=opus' }
                        : MediaRecorder.isTypeSupported('audio/wav')
                                ? { mimeType: 'audio/wav' }
                                : {}; // Fallback to default

        console.log("Using MediaRecorder options:", options);
        this.mediaRecorder = new MediaRecorder(stream, options);


        this.mediaRecorder.addEventListener('dataavailable', event => {
          if (event.data.size > 0) {
            this.audioChunks.push(event.data);
            // console.log("Audio chunk received, size:", event.data.size);
          }
        });

        this.mediaRecorder.addEventListener('stop', () => {
          console.log("MediaRecorder stopped.");
          // Stop tracks when recorder stops
          stream.getTracks().forEach(track => track.stop());
        });

        this.mediaRecorder.addEventListener('error', (event) => {
          console.error('MediaRecorder error:', event.error);
          this.voiceStatus.textContent = `خطأ في التسجيل: ${event.error.name}`;
          this.resetRecordingState();
        });


        this.mediaRecorder.start();
        this.isRecording = true;
        console.log("Recording started successfully.");

        // Update UI
        this.recordButton.classList.add('recording');
        this.buttonText.textContent = 'وقف التسجيل'; // Stop Recording
        this.voiceStatus.textContent = this.phrases.listening;

      } catch (error) {
        console.error('Error accessing microphone or starting recorder:', error);
        if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
          this.voiceStatus.textContent = 'الرجاء السماح بالوصول إلى الميكروفون.';
        } else {
          this.voiceStatus.textContent = this.phrases.micError;
        }
        this.resetRecordingState();
      }
    }

    async stopRecordingAndProcess() {
      console.log("Stopping recording...");
      if (!this.mediaRecorder || this.mediaRecorder.state === 'inactive') {
        console.warn("MediaRecorder not active or already stopped.");
        this.resetRecordingState();
        return;
      }

      this.isProcessing = true; // Start processing phase
      this.recordButton.classList.remove('recording');
      this.recordButton.classList.add('processing'); // Indicate processing
      this.recordButton.disabled = true;
      this.buttonText.textContent = 'جاري المعالجة...';
      this.voiceStatus.textContent = this.phrases.transcribing;

      // Wrap the stop logic in a promise
      const stopPromise = new Promise(resolve => {
        this.mediaRecorder.addEventListener('stop', resolve, { once: true });
        this.mediaRecorder.stop();
      });

      await stopPromise; // Wait for the 'stop' event to fire

      this.isRecording = false; // Recording is definitely stopped now

      if (this.audioChunks.length === 0) {
        console.warn("No audio chunks recorded.");
        this.voiceStatus.textContent = "لم يتم تسجيل أي صوت.";
        this.resetProcessingState();
        return;
      }


      // Determine the correct MIME type based on what was used
      const mimeType = this.mediaRecorder.mimeType || 'audio/webm'; // Default if somehow unset
      const fileExtension = mimeType.includes('wav') ? 'wav' : mimeType.includes('ogg') ? 'ogg' : 'webm';
      const audioBlob = new Blob(this.audioChunks, { type: mimeType });
      console.log(`Audio Blob created. Type: ${mimeType}, Size: ${audioBlob.size}, Extension: ${fileExtension}`);


      // Add user placeholder
      this.addMessage('...', 'user', true); // Temporary indicator
      this.showLoadingIndicator('assistant'); // Show thinking indicator for assistant

      try {
        // 1. Speech to Text
        const transcription = await this.speechToText(audioBlob, `recording.${fileExtension}`);
        console.log("Transcription:", transcription);
        this.updateLastMessage(transcription, '.user-message[data-temporary="true"]'); // Update placeholder
        this.conversationHistory.push({ role: 'user', content: transcription }); // Add to history

        // 2. Get AI Response
        this.voiceStatus.textContent = this.phrases.thinking;
        const aiReply = await this.getAIResponseFromChat();
        this.hideLoadingIndicator(); // Hide thinking indicator
        this.addMessage(aiReply, 'assistant');
        this.conversationHistory.push({ role: 'assistant', content: aiReply });

        // 3. Text to Speech
        this.voiceStatus.textContent = "جاري توليد الصوت...";
        const audioSrc = await this.textToSpeech(aiReply);

        // 4. Play Audio
        this.playAudioResponse(audioSrc); // Will update status on play/end

      } catch (error) {
        console.error('Error during processing pipeline:', error);
        this.hideLoadingIndicator();
        this.updateLastMessage(`(خطأ في النسخ: ${error.message})`, '.user-message[data-temporary="true"]'); // Update user placeholder on error
        this.addMessage(`${this.phrases.error} (${error.message})`, 'assistant');
        this.voiceStatus.textContent = 'حدث خطأ';
      } finally {
        this.resetProcessingState();
      }
    }

    // Resets button and status after processing is complete or on error
    resetRecordingState() {
      this.isRecording = false;
      this.mediaRecorder = null;
      this.audioChunks = [];
      if (this.recordButton) {
        this.recordButton.classList.remove('recording', 'processing');
        this.recordButton.disabled = false;
        this.buttonText.textContent = 'إبدأ التسجيل';
      }
      if (this.voiceStatus && !this.voiceStatus.textContent.startsWith('خطأ')) { // Don't overwrite specific errors
        this.voiceStatus.textContent = this.phrases.ready;
      }
    }
    resetProcessingState() {
      this.isProcessing = false;
      if (this.recordButton) {
        this.recordButton.classList.remove('processing');
        this.recordButton.disabled = false;
        this.buttonText.textContent = 'إبدأ التسجيل';
      }
      // Don't reset voiceStatus here immediately, let playAudioResponse handle it
    }


    addMessage(text, sender, isTemporary = false) {
      if (!this.conversationContainer) return;
      const messageElement = document.createElement('div');
      messageElement.classList.add('message', sender === 'user' ? 'user-message' : 'assistant-message');
      messageElement.textContent = text;

      if (isTemporary) {
        messageElement.setAttribute('data-temporary', 'true');
        messageElement.style.opacity = '0.7';
        messageElement.style.fontStyle = 'italic';
      } else {
        this.addTimestamp(messageElement);
      }


      this.conversationContainer.appendChild(messageElement);
      this.conversationContainer.scrollTo({ top: this.conversationContainer.scrollHeight, behavior: 'smooth' });
      return messageElement; // Return element for potential update
    }

    // Updates the content of the last message matching a selector
    updateLastMessage(newText, selector) {
      const messages = this.conversationContainer.querySelectorAll(selector);
      const lastMessage = messages[messages.length - 1];
      if (lastMessage) {
        lastMessage.textContent = newText;
        lastMessage.removeAttribute('data-temporary');
        lastMessage.style.opacity = '1';
        lastMessage.style.fontStyle = 'normal';
        this.addTimestamp(lastMessage); // Add timestamp now
      }
    }


    addTimestamp(messageElement) {
      const timeElement = document.createElement('span');
      timeElement.classList.add('message-time');
      const now = new Date();
      timeElement.textContent = `${String(now.getHours()).padStart(2, '0')}:${String(now.getMinutes()).padStart(2, '0')}`;
      messageElement.appendChild(timeElement);
    }

    showLoadingIndicator(sender = 'assistant') { // Default to assistant side
      if (!this.conversationContainer) return;
      this.hideLoadingIndicator(); // Remove previous if any
      const loadingElement = document.createElement('div');
      loadingElement.classList.add('loading');
      // Add sender class to align indicator correctly
      loadingElement.classList.add(sender === 'user' ? 'user-message' : 'assistant-message');
      loadingElement.style.background = 'transparent'; // Make background transparent
      loadingElement.style.boxShadow = 'none';
      loadingElement.style.alignSelf = (sender === 'user' ? 'flex-start' : 'flex-end'); // Align correctly

      loadingElement.setAttribute('id', 'loading-indicator');
      loadingElement.innerHTML = `<div class="loading-dots"><span></span><span></span><span></span></div>`;
      this.conversationContainer.appendChild(loadingElement);
      this.conversationContainer.scrollTo({ top: this.conversationContainer.scrollHeight, behavior: 'smooth' });
    }

    hideLoadingIndicator() {
      const indicator = document.getElementById('loading-indicator');
      indicator?.remove();
    }

    async speechToText(audioBlob, filename = 'recording.wav') {
      const formData = new FormData();
      formData.append('file', audioBlob, filename);
      formData.append('model', 'whisper-1');
      formData.append('language', 'ar'); // Specify Arabic
      formData.append('response_format', 'text'); // Request plain text

      console.log("Sending audio to Whisper API...");

      const response = await fetch(this.sttApiUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`
          // Content-Type is set automatically for FormData
        },
        body: formData
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error("Whisper API Error Text:", errorText);
        throw new Error(`Speech to text API error: ${response.status} - ${errorText}`);
      }

      const transcription = await response.text(); // Get text directly
      console.log("Transcription received:", transcription);
      return transcription;
    }

    async getAIResponseFromChat() {
      const systemPrompt = `Tu es un agent de support client IA pour "TrottiCare", un service de location de trottinettes électriques en Tunisie. Réponds aux questions des utilisateurs **exclusivement en dialecte tunisien (Derja)** de manière naturelle et conversationnelle. Tes réponses doivent concerner uniquement le service de location de trottinettes (comment louer, prix, problèmes techniques simples, localisation, paiement, règles de sécurité de base). Sois amical, patient et utilise des expressions tunisiennes courantes. Si la question est hors sujet, réponds poliment en Derja que tu ne peux aider que pour les trottinettes. Ne génère que la réponse textuelle de l'agent, sans aucune salutation ou introduction comme "Agent:", juste la réponse en Derja. Garde les réponses relativement courtes.`;

      const messagesPayload = [
        { role: 'system', content: systemPrompt },
        ...this.conversationHistory.slice(-6), // Include recent history
      ];

      console.log("Sending messages to Chat API:", messagesPayload);

      const response = await fetch(this.chatApiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini', // Or gpt-4o for potentially better dialect
          messages: messagesPayload,
          temperature: 0.7,
          max_tokens: 120 // Slightly more tokens for conversation
        })
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        const errorMsg = errorData?.error?.message || `Chat API error (${response.status})`;
        console.error("Chat API Error Response:", errorData);
        throw new Error(errorMsg);
      }

      const data = await response.json();
      console.log("Chat API Response:", data);
      if (data.choices && data.choices[0] && data.choices[0].message && data.choices[0].message.content) {
        const aiReply = data.choices[0].message.content.trim();
        console.log("AI Reply Text:", aiReply);
        return aiReply;
      } else {
        throw new Error("Unexpected response structure from Chat API");
      }
    }

    async textToSpeech(text) {
      console.log("Sending text to TTS API:", text);
      const response = await fetch(this.ttsApiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: 'tts-1', // Standard TTS model
          voice: 'alloy', // Choose voice: alloy, echo, fable, onyx, nova, shimmer
          input: text,
          response_format: 'mp3' // Or opus, aac, flac
        })
      });

      if (!response.ok) {
        const errorText = await response.text(); // Get error text for TTS
        console.error("TTS API Error Text:", errorText);
        throw new Error(`Text to speech API error: ${response.status} - ${errorText}`);
      }

      const audioBlob = await response.blob();
      console.log("TTS Audio Blob received, size:", audioBlob.size);
      return URL.createObjectURL(audioBlob); // Create URL for playback
    }

    playAudioResponse(audioSrc) {
      if (this.currentAudioPlayer) {
        this.currentAudioPlayer.pause(); // Stop previous audio if any
      }
      console.log("Playing audio response...");
      this.voiceStatus.textContent = this.phrases.speaking;

      const audio = new Audio(audioSrc);
      this.currentAudioPlayer = audio; // Store reference

      audio.play()
              .then(() => {
                console.log("Audio playback started.");
              })
              .catch(error => {
                console.error('Error playing audio:', error);
                this.voiceStatus.textContent = 'خطأ في تشغيل الصوت';
                this.resetProcessingState(); // Reset button state on playback error
              });

      // Update status when audio finishes
      audio.onended = () => {
        console.log("Audio playback finished.");
        URL.revokeObjectURL(audioSrc); // Clean up blob URL
        this.currentAudioPlayer = null;
        if (!this.isProcessing) { // Only reset status if not immediately processing next step
          this.voiceStatus.textContent = this.phrases.ready;
        }
      };
      // Also update status on error during playback
      audio.onerror = () => {
        console.error('Audio playback error event.');
        URL.revokeObjectURL(audioSrc);
        this.currentAudioPlayer = null;
        if (!this.isProcessing) {
          this.voiceStatus.textContent = 'خطأ في تشغيل الصوت';
          this.resetProcessingState();
        }
      };
    }
  }

  // --- INITIALIZE THE CLASS ---
  document.addEventListener('DOMContentLoaded', () => {
    if (document.querySelector('.voice-support-container')) {
      window.voiceSupportSimplePOC = new TunisianRealtimeVoicePOC();
    } else {
      console.warn("Voice support container not found.");
    }
  });
</script>

</body>
</html>